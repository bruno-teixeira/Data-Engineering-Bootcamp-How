{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cbb96f0",
   "metadata": {},
   "source": [
    "# 06.10\n",
    "\n",
    "**Turma 06** - 88 Inscritos\n",
    "\n",
    "**Cohort** = Modelo de aprendizado em grupo\n",
    "\n",
    "**Duvidas tecnicas** = Rodrigo Azevedo\n",
    "\n",
    "**Facilitadores** = André Sionek | Rhuan Lima | Rafael Dias\n",
    "\n",
    "**Discord** = canal de avisos-outrubro-2022\n",
    "\n",
    "**Certificado** = 70% do conteudo gravado concluido + 3 CheckPoints\n",
    "Marcar modulos como concluido\n",
    "\n",
    "10 Semanas = Encontros toda quinta 19h30 - 22h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7b380",
   "metadata": {},
   "source": [
    "# Funções para um Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97873d58",
   "metadata": {},
   "source": [
    "## Infra/Plataforma\n",
    "\n",
    "Criar e manter infra de dados\n",
    "\n",
    "- DataOps - Evolução do DBA\n",
    "- Responsavel pela estrutura de dados : DL/DW/LH\n",
    "- Streaming de dados\n",
    "- Pipelines de testes automatizados \n",
    "- Facilitar o time de dados\n",
    "- Boas praticas na utilização da arquitetura de dados\n",
    "- Ferramentas = Terraform, Cloudformation, Kafka, Cloudwatch\n",
    "\n",
    "\n",
    "Ferramentas | Descrição\n",
    ":--------- | :-----\n",
    "Terraform | stack de desenvolvimento de dw para cloud\n",
    "Kafka | streaming de dados\n",
    "Hive | governança dos dados\n",
    "Cloudwatch | agendamentos de ETL na AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49e217e",
   "metadata": {},
   "source": [
    "## Criação e Gestão de Pipelines\n",
    "\n",
    "Criar e manter o fluxo de dados das fontes para as áreas clientes\n",
    "\n",
    "- Area mais demandada\n",
    "- Scripts de extração de dados por API e DB\n",
    "- Crawlers para extração de dados da Web (scrapping = massivo / crawler = pontual)\n",
    "- DAGs no Airflow\n",
    "- ETLs e higienização dos dados\n",
    "- Ferramentas = Airflow, Spark, Pandas, SQL, Lambda, Buckets\n",
    "\n",
    "\n",
    "Ferramentas | Descrição\n",
    ":--------- | :------\n",
    "Airflow | orquestração de tarefas/ETL\n",
    "Buckets | armazentamento de arquivos S3 da AWS\n",
    "DBT | ferramenta de ELT com gestão de piple/gestão de dependencias/governança\n",
    "Dataforms | parecido do DBT\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f25c5fc",
   "metadata": {},
   "source": [
    "## MLOps\n",
    "\n",
    "Colocar modelos de AI e ML em produção e acompanhar qualidade\n",
    "\n",
    "- Amigo do Cientista de Dados\n",
    "- Deploy e acompanhamento dos modelos\n",
    "- Cria pipeline para envio e recebimento de requisições\n",
    "- Monitora o desempenho dos modelos\n",
    "- Ferramentas = Docker, Kubernetes, API'& Endpoints', SQL, Python, R, Java, Spark\n",
    "\n",
    "\n",
    "Ferramentas | Descrição\n",
    ":--------- | :------\n",
    "Docker | Parecido com maquina virtual, documento com os requisitos necessario para efetuar uma task, infinitamente mais leve, facil de manipular e level\n",
    "Kubernets | Combinação de Dockers\n",
    "API Endpoints | Comunicação dos dados com os modelos\n",
    "Spark | n maquinas com clusters de processamento horizontal separado em workers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3db729",
   "metadata": {},
   "source": [
    "## Analytics\n",
    "Aplicar regras de negócios e criar modelos de dados para serem consultados pelo business\n",
    "\n",
    "- Próximo a BI\n",
    "- KPIO, OKR, MC1, MC2 (Margem de Contribuição)\n",
    "- Diferentes fontes para criar visão unica\n",
    "- Fatos x Dimensões\n",
    "- Modelagem Snowflake/Star-Schema\n",
    "- Ferramentas: SQL, NoSQL, DBT, Airflow, Tableau, PowerBI, Python, R\n",
    "\n",
    "Ferramentas | Descrição \n",
    ":--------- | :---------\n",
    "Tableau/PowerBI | Visualização de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633c696f",
   "metadata": {},
   "source": [
    "# Senioridade\n",
    "\n",
    "## Jr\n",
    "\n",
    "- Manter pipelines existentes\n",
    "- Cria ingestão de dados simples\n",
    "\n",
    "## Pl\n",
    "\n",
    "- Implementa novos pipelines de dados\n",
    "- Cria ingestão de dados batch\n",
    "- Tem contato com área de negócios\n",
    "- Propõe novas maneiras de ingestão de dados\n",
    "\n",
    "## Sr\n",
    "\n",
    "- Cria e implementa novos pipelines de dados\n",
    "- Cria ingestão de dados batch e stream\n",
    "- Propõe novas arquiteturas de gestão de dados em Multicloud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e80fb8",
   "metadata": {},
   "source": [
    "# Outros Recursos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ef5929",
   "metadata": {},
   "source": [
    "## Python\n",
    "\n",
    "- Codecademy\n",
    "- Alura\n",
    "- Coursera\n",
    "- Udemy\n",
    "- Datacamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b774cf24",
   "metadata": {},
   "source": [
    "## Cloud Infra\n",
    "\n",
    "- Oracle\n",
    "- Google Cloud Platafor\n",
    "- AWS \n",
    "- Azure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027e4c12",
   "metadata": {},
   "source": [
    "## Spark\n",
    "\n",
    "- Udemy\n",
    "- Alura\n",
    "- Coursera\n",
    "- Databricks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
